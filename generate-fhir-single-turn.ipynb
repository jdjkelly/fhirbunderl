{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DH5ERzE9PNB1"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LYjxkMgPNB1"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVnsl2SWPNB2",
        "outputId": "e508a07e-af34-4b96-9542-f2f9f8d26364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 82ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install dotenv \"numpy<2.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j6CZjq3PNB2",
        "outputId": "24e06b19-7c96-4eac-db88-fb0291702a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 109ms\u001b[0m\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install openpipe-art openpipe --prerelease allow --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-FH24--PNB2"
      },
      "source": [
        "# Environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kef7yChdPNB2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Optional\n",
        "WANDB_API_KEY = \"\"\n",
        "if WANDB_API_KEY:\n",
        "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
        "\n",
        "# Optional\n",
        "OPENPIPE_API_KEY = \"\"\n",
        "if OPENPIPE_API_KEY:\n",
        "    os.environ[\"OPENPIPE_API_KEY\"] = OPENPIPE_API_KEY\n",
        "\n",
        "MODEL_NAME = \"001\"\n",
        "PROJECT = \"generate-fhir-single-turn\"\n",
        "BASE_MODEL = \"Qwen/Qwen2.5-7B-Instruct\"\n",
        "LEARNING_RATE = 1.2e-5\n",
        "GROUPS_PER_STEP = 1\n",
        "EVAL_STEPS = 50\n",
        "VAL_SET_SIZE = 100\n",
        "NUM_EPOCHS = 1\n",
        "NUM_GENERATIONS = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lk8f_9PPNB2"
      },
      "source": [
        "# Main loop"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate Tool"
      ],
      "metadata": {
        "id": "Vom_kng7fmcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from typing import Dict, Any, Union, List, Optional\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "\n",
        "@dataclass\n",
        "class ValidationResult:\n",
        "    \"\"\"Result of FHIR resource validation from server\"\"\"\n",
        "    is_valid: bool\n",
        "    errors: List[str]\n",
        "    warnings: List[str]\n",
        "    information: List[str]\n",
        "    resource_type: str = None\n",
        "    timestamp: str = None\n",
        "    operation_outcome: Dict[str, Any] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.timestamp is None:\n",
        "            self.timestamp = datetime.utcnow().isoformat()\n",
        "\n",
        "def validate_fhir_resource(\n",
        "    resource_json: Union[str, Dict[str, Any]],\n",
        "    fhir_server_url: str,\n",
        "    resource_type: Optional[str] = None,\n",
        "    profile_url: Optional[str] = None,\n",
        "    timeout: int = 30\n",
        ") -> ValidationResult:\n",
        "    \"\"\"\n",
        "    Validate a FHIR resource by making a REST call to a FHIR server's validation endpoint.\n",
        "\n",
        "    Args:\n",
        "        resource_json: FHIR resource as JSON string or dictionary\n",
        "        fhir_server_url: Base URL of the FHIR server (e.g., \"https://hapi.fhir.org/baseR4\")\n",
        "        resource_type: Optional resource type for validation endpoint (e.g., \"Patient\")\n",
        "        profile_url: Optional profile URL to validate against\n",
        "        timeout: Request timeout in seconds (default: 30)\n",
        "\n",
        "    Returns:\n",
        "        ValidationResult: Object containing validation status, errors, and warnings\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    warnings = []\n",
        "    information = []\n",
        "    detected_resource_type = None\n",
        "    operation_outcome = None\n",
        "\n",
        "    try:\n",
        "        # Parse JSON if string input\n",
        "        if isinstance(resource_json, str):\n",
        "            try:\n",
        "                resource_dict = json.loads(resource_json)\n",
        "            except json.JSONDecodeError as e:\n",
        "                return ValidationResult(\n",
        "                    is_valid=False,\n",
        "                    errors=[f\"Invalid JSON format: {str(e)}\"],\n",
        "                    warnings=[],\n",
        "                    information=[]\n",
        "                )\n",
        "        else:\n",
        "            resource_dict = resource_json\n",
        "\n",
        "        # Extract resource type from the resource\n",
        "        if isinstance(resource_dict, dict) and 'resourceType' in resource_dict:\n",
        "            detected_resource_type = resource_dict['resourceType']\n",
        "\n",
        "        # Prepare validation endpoint URL\n",
        "        fhir_base_url = fhir_server_url.rstrip('/')\n",
        "\n",
        "        # Build validation URL - can be specific to resource type or general\n",
        "        if resource_type:\n",
        "            validation_url = f\"{fhir_base_url}/{resource_type}/$validate\"\n",
        "        elif detected_resource_type:\n",
        "            validation_url = f\"{fhir_base_url}/{detected_resource_type}/$validate\"\n",
        "        else:\n",
        "            validation_url = f\"{fhir_base_url}/$validate\"\n",
        "\n",
        "        # Prepare request headers\n",
        "        headers = {\n",
        "            'Content-Type': 'application/fhir+json',\n",
        "            'Accept': 'application/fhir+json'\n",
        "        }\n",
        "\n",
        "        # Add profile parameter if specified\n",
        "        params = {}\n",
        "        if profile_url:\n",
        "            params['profile'] = profile_url\n",
        "\n",
        "        # Make the validation request\n",
        "        response = requests.post(\n",
        "            validation_url,\n",
        "            json=resource_dict,\n",
        "            headers=headers,\n",
        "            params=params,\n",
        "            timeout=timeout\n",
        "        )\n",
        "\n",
        "        # Parse the response\n",
        "        if response.status_code == 200:\n",
        "            # Successful validation - parse OperationOutcome\n",
        "            try:\n",
        "                operation_outcome = response.json()\n",
        "                is_valid, parsed_errors, parsed_warnings, parsed_info = _parse_operation_outcome(operation_outcome)\n",
        "                errors.extend(parsed_errors)\n",
        "                warnings.extend(parsed_warnings)\n",
        "                information.extend(parsed_info)\n",
        "\n",
        "            except json.JSONDecodeError:\n",
        "                errors.append(\"Server returned invalid JSON response\")\n",
        "\n",
        "        elif response.status_code == 400:\n",
        "            # Bad request - usually means validation failed\n",
        "            try:\n",
        "                operation_outcome = response.json()\n",
        "                is_valid, parsed_errors, parsed_warnings, parsed_info = _parse_operation_outcome(operation_outcome)\n",
        "                errors.extend(parsed_errors)\n",
        "                warnings.extend(parsed_warnings)\n",
        "                information.extend(parsed_info)\n",
        "            except json.JSONDecodeError:\n",
        "                errors.append(f\"Validation failed with status {response.status_code}: {response.text}\")\n",
        "\n",
        "        elif response.status_code == 404:\n",
        "            errors.append(\"FHIR server validation endpoint not found - check server URL and resource type\")\n",
        "\n",
        "        elif response.status_code == 422:\n",
        "            # Unprocessable Entity - validation errors\n",
        "            try:\n",
        "                operation_outcome = response.json()\n",
        "                is_valid, parsed_errors, parsed_warnings, parsed_info = _parse_operation_outcome(operation_outcome)\n",
        "                errors.extend(parsed_errors)\n",
        "                warnings.extend(parsed_warnings)\n",
        "                information.extend(parsed_info)\n",
        "            except json.JSONDecodeError:\n",
        "                errors.append(f\"Validation failed with status {response.status_code}: {response.text}\")\n",
        "\n",
        "        else:\n",
        "            errors.append(f\"FHIR server returned status {response.status_code}: {response.text}\")\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        errors.append(f\"Request to FHIR server timed out after {timeout} seconds\")\n",
        "\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        errors.append(\"Could not connect to FHIR server - check URL and network connectivity\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        errors.append(f\"Request to FHIR server failed: {str(e)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        errors.append(f\"Unexpected error during validation: {str(e)}\")\n",
        "\n",
        "    return ValidationResult(\n",
        "        is_valid=len(errors) == 0,\n",
        "        errors=errors,\n",
        "        warnings=warnings,\n",
        "        information=information,\n",
        "        resource_type=detected_resource_type,\n",
        "        operation_outcome=operation_outcome\n",
        "    )\n",
        "\n",
        "def _parse_operation_outcome(operation_outcome: Dict[str, Any]) -> tuple[bool, List[str], List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Parse FHIR OperationOutcome resource to extract validation results.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (is_valid, errors, warnings, information)\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "    warnings = []\n",
        "    information = []\n",
        "    is_valid = True\n",
        "\n",
        "    if not isinstance(operation_outcome, dict):\n",
        "        errors.append(\"Invalid OperationOutcome format\")\n",
        "        return False, errors, warnings, information\n",
        "\n",
        "    # Check if it's actually an OperationOutcome resource\n",
        "    if operation_outcome.get('resourceType') != 'OperationOutcome':\n",
        "        errors.append(\"Expected OperationOutcome resource from validation endpoint\")\n",
        "        return False, errors, warnings, information\n",
        "\n",
        "    # Parse issues from OperationOutcome\n",
        "    issues = operation_outcome.get('issue', [])\n",
        "\n",
        "    for issue in issues:\n",
        "        if not isinstance(issue, dict):\n",
        "            continue\n",
        "\n",
        "        severity = issue.get('severity', 'error')\n",
        "        code = issue.get('code', 'unknown')\n",
        "        details = issue.get('details', {})\n",
        "        diagnostics = issue.get('diagnostics', '')\n",
        "        location = issue.get('location', [])\n",
        "\n",
        "        # Build error message\n",
        "        message_parts = []\n",
        "\n",
        "        if details and isinstance(details, dict):\n",
        "            detail_text = details.get('text', '')\n",
        "            if detail_text:\n",
        "                message_parts.append(detail_text)\n",
        "\n",
        "        if diagnostics:\n",
        "            message_parts.append(diagnostics)\n",
        "\n",
        "        if location:\n",
        "            location_str = ', '.join(location)\n",
        "            message_parts.append(f\"Location: {location_str}\")\n",
        "\n",
        "        if not message_parts:\n",
        "            message_parts.append(f\"Validation issue ({code})\")\n",
        "\n",
        "        message = ' - '.join(message_parts)\n",
        "\n",
        "        # Categorize by severity\n",
        "        if severity in ['fatal', 'error']:\n",
        "            errors.append(f\"Error: {message}\")\n",
        "            is_valid = False\n",
        "        elif severity == 'warning':\n",
        "            warnings.append(f\"Warning: {message}\")\n",
        "        elif severity == 'information':\n",
        "            information.append(f\"Info: {message}\")\n",
        "\n",
        "    # If no issues but we have an OperationOutcome, it might be successful\n",
        "    if not issues and operation_outcome.get('resourceType') == 'OperationOutcome':\n",
        "        information.append(\"Validation completed successfully\")\n",
        "\n",
        "    return is_valid, errors, warnings, information"
      ],
      "metadata": {
        "id": "Csl0unElfflD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model creation and data load"
      ],
      "metadata": {
        "id": "5FgM50Qid27g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174,
          "referenced_widgets": [
            "86d4d357893b4862ba1afebe636634af",
            "f6724304c9fd4469b9f956d07417212c",
            "889cab469f524d44b83dcce6efe06918",
            "ee1e0102689048fe813b5b3394bd9815",
            "c89df77d6a5444b49cef4290b2114b3f",
            "019da4281d9b4494964da292f1d118dc",
            "c79bed6d89bd4747a8abf3d78e51102c",
            "dac186c1cd994cdaa69334a51cecdc2c",
            "e7aeb431500545c2891ca06e0301cb72",
            "e6a526707f83490798d52d6bfa662bff",
            "4ea865b14632429aa88cbb984c7d6950"
          ]
        },
        "id": "_43P2rUWPNB2",
        "outputId": "5674d81d-9a22-4bd2-f6ea-ba655367752e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data...\n",
            "Training data size: 1\n",
            "Starting training from global step 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Iterating dataset:   0%|          | 0/1 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86d4d357893b4862ba1afebe636634af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['train']\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "import art\n",
        "from art.local import LocalBackend\n",
        "from openpipe import AsyncOpenPipe\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "backend = LocalBackend(\n",
        "    # Normally we don't want to run the server in-process, but for the output\n",
        "    # to show up properly on Google Colab we'll enable this.\n",
        "    in_process=True,\n",
        "    path=\"./.art\"\n",
        ")\n",
        "model = art.TrainableModel(\n",
        "    name=MODEL_NAME,\n",
        "    project=PROJECT,\n",
        "    base_model=BASE_MODEL,\n",
        "    _internal_config=art.dev.InternalModelConfig(\n",
        "        init_args=art.dev.InitArgs(\n",
        "            gpu_memory_utilization=0.75,\n",
        "        ),\n",
        "        peft_args=art.dev.PeftArgs(\n",
        "            lora_alpha=8,\n",
        "        ),\n",
        "        trainer_args=art.dev.TrainerArgs(\n",
        "            max_grad_norm=0.1,\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "await model.register(backend)\n",
        "op_client = AsyncOpenPipe(api_key=os.getenv(\"OPENPIPE_API_KEY\"))\n",
        "\n",
        "## Load the training data\n",
        "print(\"Loading training data...\")\n",
        "train_dataset: datasets.Dataset = datasets.load_dataset(\"jdjkelly/fhir_synthetic_snippets\")\n",
        "\n",
        "train_data_list: List[Dict[str, Any]] = list(train_dataset)  # type: ignore\n",
        "print(f\"Training data size: {len(train_data_list)}\")\n",
        "\n",
        "# Get OpenAI Client for the ART Model\n",
        "openai_client = model.openai_client()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rollout"
      ],
      "metadata": {
        "id": "LLrYfCb6d6Ti"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjOrfbfOPNB2"
      },
      "outputs": [],
      "source": [
        "# for batch_inputs, epoch, global_step, epoch_step in data_iterator:\n",
        "#   print(batch_inputs)\n",
        "#   print(epoch)\n",
        "#   print(global_step)\n",
        "#   print(epoch_step)\n",
        "#   break\n",
        "from pydantic import BaseModel\n",
        "import requests\n",
        "import openai\n",
        "\n",
        "class GenerateFhirBundle(BaseModel):\n",
        "    step: int\n",
        "\n",
        "@art.retry(exceptions=(openai.LengthFinishReasonError, requests.ReadTimeout))\n",
        "async def rollout(\n",
        "    model: art.Model,\n",
        "    row: Dict[str, Any],\n",
        ") -> art.Trajectory:\n",
        "    game = generate_game()\n",
        "\n",
        "    move_number = 0\n",
        "\n",
        "    trajectory = art.Trajectory(\n",
        "        messages_and_choices=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"\n",
        "You are a health informaticist expert in FHIR.\n",
        "You will receive unstructured notes and you need to structure them into FHIR resources.\n",
        "You must only include data that is present in the note.\n",
        "You must only return a valid FHIR JSON Bundle, with the appropriate resources, with no additional explanation.\n",
        "You may include multiple resources in the bundle.\n",
        "You must follow the FHIR R4 specification.\n",
        "You mut not include a meta element in the resources.\n",
        "When generating a CodeableConcept, you must include a coding element with a system, code, and display.\n",
        "When generating a CodeableConcept, you must use a display matching what is expected by the CodeSystem.\n",
        "Each entry in a Bundle must have a fullUrl which is the identity of the resource in the entry.\n",
        "The id of a resource must be a valid UUID in lowercase.\n",
        "\n",
        "You have access to a validator tool that will validate the FHIR bundle.\n",
        "You should use this tool recursively to fix errors, using it again after you have called it to ensure that FHIR resources are fully valid after making changes.\n",
        "\n",
        "Include the FHIR JSON bundle in your final response.\n",
        "<note>\n",
        "{{note}}\n",
        "</note>\n",
        "\"\"\",\n",
        "            }\n",
        "        ],\n",
        "        reward=0,\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        trajectory.messages_and_choices.append(\n",
        "            {\"role\": \"user\", \"content\": render_board(game)}\n",
        "        )\n",
        "\n",
        "        requested_at = int(time.time() * 1000)\n",
        "        messages = trajectory.messages()\n",
        "\n",
        "        async def get_completion():\n",
        "            client = model.openai_client()\n",
        "            return await client.chat.completions.create(\n",
        "                max_completion_tokens=128,\n",
        "                messages=messages,\n",
        "                model=model.name,\n",
        "            )\n",
        "\n",
        "        try:\n",
        "            chat_completion = await get_completion()\n",
        "            last_completion = chat_completion\n",
        "        except openai.LengthFinishReasonError as e:\n",
        "            raise e\n",
        "        except Exception as e:\n",
        "            print(\"caught exception generating chat completion\", e)\n",
        "            raise e\n",
        "\n",
        "        try:\n",
        "            if op_client.api_key:\n",
        "                await op_client.report(\n",
        "                    requested_at=requested_at,\n",
        "                    received_at=int(time.time() * 1000),\n",
        "                    req_payload={\n",
        "                        \"model\": model.name,\n",
        "                        \"messages\": messages,\n",
        "                        \"metadata\": {\n",
        "                            \"game_id\": game[\"id\"],\n",
        "                            \"notebook-id\": \"2048\",\n",
        "                            \"step\": str(scenario.step),\n",
        "                            \"move_number\": str(move_number),\n",
        "                        },\n",
        "                    },\n",
        "                    resp_payload=chat_completion,\n",
        "                    status_code=200,\n",
        "                )\n",
        "        except Exception as e:\n",
        "            print(f\"Error reporting to OpenPipe: {e}\")\n",
        "\n",
        "        choice = chat_completion.choices[0]\n",
        "        content = choice.message.content\n",
        "        assert isinstance(content, str)\n",
        "        trajectory.messages_and_choices.append(choice)\n",
        "\n",
        "        try:\n",
        "            apply_agent_move(game, content)\n",
        "            move_number += 1\n",
        "        except ValueError:\n",
        "            trajectory.reward = -1\n",
        "            break\n",
        "\n",
        "        if check_game_finished(game):\n",
        "            max_value = max_cell_value(game)\n",
        "            board_value = total_board_value(game)\n",
        "            trajectory.metrics[\"max_value\"] = max_value\n",
        "            trajectory.metrics[\"board_value\"] = board_value\n",
        "\n",
        "            if max_value < WINNING_VALUE:\n",
        "                # scale max value logarithmically between 0 for 2 and 1 for WINNING_VALUE\n",
        "                max_value_reward = (math.log(max_value, 2) - 1) / (\n",
        "                    math.log(WINNING_VALUE, 2) - 1\n",
        "                )\n",
        "                # scale board value logarithmically between 0 for 2 * 16 and 1 for WINNING_VALUE * 16\n",
        "                board_value_reward = (math.log(board_value, 2) - 1) / (\n",
        "                    math.log(WINNING_VALUE * 16, 2) - 1\n",
        "                )\n",
        "                # combine the two rewards, with max value having a higher weight\n",
        "                trajectory.reward = max_value_reward + (board_value_reward * 0.2)\n",
        "            else:\n",
        "                # double reward if the agent wins\n",
        "                trajectory.reward = 2\n",
        "            break\n",
        "\n",
        "    try:\n",
        "        if op_client.api_key:\n",
        "            await op_client.update_log_metadata(\n",
        "                filters=[\n",
        "                    {\n",
        "                        \"field\": \"completionId\",\n",
        "                        \"equals\": last_completion.id,\n",
        "                    }\n",
        "                ],\n",
        "                metadata={\n",
        "                    \"reward\": str(trajectory.reward),\n",
        "                    \"reward_assigned\": \"true\",\n",
        "                },\n",
        "            )\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating log metadata: {e}\")\n",
        "\n",
        "    return trajectory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop\n",
        "\n"
      ],
      "metadata": {
        "id": "Jtkjp4t9eJLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_step = await model.get_step()\n",
        "print(f\"Starting training from global step {start_step}\")\n",
        "\n",
        "data_iterator = art.utils.iterate_dataset(\n",
        "    dataset=train_data_list,\n",
        "    groups_per_step=GROUPS_PER_STEP,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    initial_step=start_step,\n",
        "    use_tqdm=True,\n",
        ")\n",
        "\n",
        "for i in range(await model.get_step(), 10):\n",
        "    train_groups = await art.gather_trajectory_groups(\n",
        "        (\n",
        "            art.TrajectoryGroup(\n",
        "                rollout(model, Scenario2048(step=i)) for _ in range(18)\n",
        "            )\n",
        "            for _ in range(1)\n",
        "        ),\n",
        "        pbar_desc=\"gather\",\n",
        "        max_exceptions=18,\n",
        "    )\n",
        "    await model.delete_checkpoints()\n",
        "    await model.train(\n",
        "        train_groups,\n",
        "        config=art.TrainConfig(learning_rate=3e-5),\n",
        "        # Lowering the logprob_calculation_chunk_size is a memory saving measure\n",
        "        # to allow longer sequences (up to 4096 tokens) to be processed on a T4.\n",
        "        _config={\"logprob_calculation_chunk_size\": 8},\n",
        "    )"
      ],
      "metadata": {
        "id": "UNZoSKULeRz_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "86d4d357893b4862ba1afebe636634af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6724304c9fd4469b9f956d07417212c",
              "IPY_MODEL_889cab469f524d44b83dcce6efe06918",
              "IPY_MODEL_ee1e0102689048fe813b5b3394bd9815"
            ],
            "layout": "IPY_MODEL_c89df77d6a5444b49cef4290b2114b3f"
          }
        },
        "f6724304c9fd4469b9f956d07417212c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_019da4281d9b4494964da292f1d118dc",
            "placeholder": "​",
            "style": "IPY_MODEL_c79bed6d89bd4747a8abf3d78e51102c",
            "value": "Iterating dataset:   0%"
          }
        },
        "889cab469f524d44b83dcce6efe06918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dac186c1cd994cdaa69334a51cecdc2c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7aeb431500545c2891ca06e0301cb72",
            "value": 0
          }
        },
        "ee1e0102689048fe813b5b3394bd9815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a526707f83490798d52d6bfa662bff",
            "placeholder": "​",
            "style": "IPY_MODEL_4ea865b14632429aa88cbb984c7d6950",
            "value": " 0/1 [00:00&lt;?, ?batch/s]"
          }
        },
        "c89df77d6a5444b49cef4290b2114b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019da4281d9b4494964da292f1d118dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c79bed6d89bd4747a8abf3d78e51102c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dac186c1cd994cdaa69334a51cecdc2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7aeb431500545c2891ca06e0301cb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6a526707f83490798d52d6bfa662bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ea865b14632429aa88cbb984c7d6950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}