{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (1.84.0)\n",
            "Requirement already satisfied: datasets in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (3.6.0)\n",
            "Requirement already satisfied: pandas in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (2.3.0)\n",
            "Requirement already satisfied: tqdm in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (4.67.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from openai) (2.11.5)\n",
            "Requirement already satisfied: sniffio in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: filelock in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (2.2.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (20.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set up dependencies\n",
        "%pip install openai datasets pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/joshuakelly/flexpa/flexpa/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "from openai import OpenAI\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Define comprehensive list of FHIR resources\n",
        "FHIR_RESOURCES = [\n",
        "    \"Patient\", \"Practitioner\", \"Organization\", \"Location\", \"Device\",\n",
        "    \"Observation\", \"DiagnosticReport\", \"Condition\", \"Procedure\", \"MedicationRequest\",\n",
        "    \"MedicationAdministration\", \"MedicationDispense\", \"MedicationStatement\", \"Immunization\",\n",
        "    \"AllergyIntolerance\", \"Encounter\", \"Appointment\", \"AppointmentResponse\",\n",
        "    \"CarePlan\", \"CareTeam\", \"Goal\", \"ServiceRequest\", \"Task\",\n",
        "    \"DocumentReference\", \"Binary\", \"Media\", \"Composition\", \"DiagnosticReport\",\n",
        "    \"Specimen\", \"ImagingStudy\", \"QuestionnaireResponse\", \"Questionnaire\",\n",
        "    \"Coverage\", \"ExplanationOfBenefit\", \"Claim\", \"ClaimResponse\", \"PaymentNotice\",\n",
        "    \"Invoice\", \"Account\", \"ChargeItem\", \"Contract\", \"EnrollmentRequest\",\n",
        "    \"VisionPrescription\", \"NutritionOrder\", \"SupplyRequest\", \"SupplyDelivery\",\n",
        "    \"BiologicallyDerivedProduct\", \"ResearchStudy\", \"ResearchSubject\", \"ActivityDefinition\",\n",
        "    \"PlanDefinition\", \"Measure\", \"MeasureReport\", \"Library\", \"GuidanceResponse\",\n",
        "    \"RiskAssessment\", \"DetectedIssue\", \"ClinicalImpression\", \"FamilyMemberHistory\",\n",
        "    \"Group\", \"Person\", \"RelatedPerson\", \"Endpoint\", \"HealthcareService\",\n",
        "    \"InsurancePlan\", \"SubstanceSpecification\", \"MolecularSequence\", \"ImmunizationEvaluation\",\n",
        "    \"ImmunizationRecommendation\", \"AdverseEvent\", \"Flag\", \"List\", \"Linkage\",\n",
        "    \"AuditEvent\", \"Provenance\", \"Consent\", \"Communication\", \"CommunicationRequest\",\n",
        "    \"DeviceRequest\", \"DeviceUseStatement\", \"DeviceMetric\", \"Substance\", \"Medication\",\n",
        "    \"MedicinalProduct\", \"Schedule\", \"Slot\",\n",
        "    \"Bundle\", \"MessageHeader\", \"MessageDefinition\", \"EventDefinition\", \"ObservationDefinition\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "async def generate_fhir_statement_async(resource_type):\n",
        "    \"\"\"Generate a short healthcare statement about a FHIR resource (async version)\"\"\"\n",
        "    prompt = f\"\"\"Generate a single, concise statement describing a healthcare scenario, object, or event that could be represented by a {resource_type} FHIR resource.\n",
        "    \n",
        "    The statement should:\n",
        "    - Be medically accurate and realistic\n",
        "    - Be between 10-25 words\n",
        "    - Use everyday language that healthcare professionals would understand\n",
        "    - Focus on a specific clinical scenario or use case\n",
        "    - NOT use the word \"FHIR\" in the sentence\n",
        "    - NOT directly reference the canonical name of the resource type in the sentence (i.e. patient is okay but Patient is not)\n",
        "    \n",
        "    Examples for other resources:\n",
        "    - Patient: \"A patient John Smith was admitted to the emergency department with chest pain complaints.\"\n",
        "    - Observation: \"Blood pressure observation shows elevated systolic reading of 180 mmHg during routine check-up.\"\n",
        "    - Medication: \"Prescribed medication includes daily 10mg lisinopril for hypertension management.\"\n",
        "    \n",
        "    Generate one statement for {resource_type}:\"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Run the synchronous OpenAI call in a thread pool\n",
        "        loop = asyncio.get_event_loop()\n",
        "        response = await loop.run_in_executor(\n",
        "            None,\n",
        "            lambda: client.chat.completions.create(\n",
        "                model=\"gpt-4.1-mini\",  # Fixed model name\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                max_tokens=100,\n",
        "                temperature=0.8\n",
        "            )\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating statement for {resource_type}: {e}\")\n",
        "        return None\n",
        "\n",
        "async def create_synthetic_dataset_parallel(target_count=1000, batch_size=10):\n",
        "    \"\"\"Create synthetic FHIR dataset with parallel processing\"\"\"\n",
        "    \n",
        "    data = []\n",
        "    failed_generations = 0\n",
        "    \n",
        "    print(f\"Generating {target_count} synthetic FHIR healthcare statements with {batch_size} parallel requests...\")\n",
        "    \n",
        "    # Calculate how many examples per resource type\n",
        "    examples_per_resource = target_count // len(FHIR_RESOURCES)\n",
        "    remaining_examples = target_count % len(FHIR_RESOURCES)\n",
        "    \n",
        "    # Create list of all tasks\n",
        "    tasks = []\n",
        "    for i, resource_type in enumerate(FHIR_RESOURCES):\n",
        "        count_for_this_resource = examples_per_resource + (1 if i < remaining_examples else 0)\n",
        "        tasks.extend([resource_type] * count_for_this_resource)\n",
        "    \n",
        "    # Process in batches\n",
        "    with tqdm(total=len(tasks), desc=\"Generating statements\") as pbar:\n",
        "        for i in range(0, len(tasks), batch_size):\n",
        "            batch = tasks[i:i + batch_size]\n",
        "            \n",
        "            # Create async tasks for this batch\n",
        "            batch_tasks = [generate_fhir_statement_async(resource_type) for resource_type in batch]\n",
        "            \n",
        "            # Run batch concurrently\n",
        "            results = await asyncio.gather(*batch_tasks)\n",
        "            \n",
        "            # Process results\n",
        "            for j, statement in enumerate(results):\n",
        "                resource_type = batch[j]\n",
        "                if statement:\n",
        "                    data.append({\n",
        "                        \"statement\": statement,\n",
        "                        \"resource_type\": resource_type,\n",
        "                        \"id\": len(data)\n",
        "                    })\n",
        "                else:\n",
        "                    failed_generations += 1\n",
        "                    fallback = f\"Healthcare record contains {resource_type} information for patient care documentation.\"\n",
        "                    data.append({\n",
        "                        \"statement\": fallback,\n",
        "                        \"resource_type\": resource_type,\n",
        "                        \"id\": len(data)\n",
        "                    })\n",
        "            \n",
        "            pbar.update(len(batch))\n",
        "    \n",
        "    print(f\"Generated {len(data)} statements successfully\")\n",
        "    print(f\"Failed generations (used fallbacks): {failed_generations}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Note: In Jupyter, we'll call the async function directly with await\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating synthetic FHIR dataset...\n",
            "Generating 1000 synthetic FHIR healthcare statements with 5 parallel requests...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating statements: 100%|██████████| 1000/1000 [03:55<00:00,  4.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 1000 statements successfully\n",
            "Failed generations (used fallbacks): 0\n",
            "Generated 1000 examples\n",
            "\n",
            "Sample data:\n",
            "                                           statement resource_type  id\n",
            "0  A 45-year-old female with a history of diabete...       Patient   0\n",
            "1  A 45-year-old female with diabetes is register...       Patient   1\n",
            "2  A 45-year-old female with a history of diabete...       Patient   2\n",
            "3  A 45-year-old female with diabetes and hyperte...       Patient   3\n",
            "4  A 45-year-old female with a history of diabete...       Patient   4\n",
            "\n",
            "Created Hugging Face dataset with 1000 examples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 338769.40 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset saved to './fhir_synthetic_dataset'\n",
            "Dataset also saved as 'fhir_synthetic_data.json'\n",
            "\n",
            "Dataset statistics:\n",
            "Total examples: 1000\n",
            "Unique resource types: 90\n",
            "Examples per resource type (top 10):\n",
            "resource_type\n",
            "DiagnosticReport          22\n",
            "Patient                   11\n",
            "FamilyMemberHistory       11\n",
            "ImmunizationEvaluation    11\n",
            "MolecularSequence         11\n",
            "SubstanceSpecification    11\n",
            "InsurancePlan             11\n",
            "HealthcareService         11\n",
            "Endpoint                  11\n",
            "RelatedPerson             11\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate the dataset using the async parallel function\n",
        "print(\"Creating synthetic FHIR dataset...\")\n",
        "synthetic_data = await create_synthetic_dataset_parallel(1000, batch_size=5)\n",
        "\n",
        "# Convert to pandas DataFrame for easier manipulation\n",
        "df = pd.DataFrame(synthetic_data)\n",
        "print(f\"Generated {len(df)} examples\")\n",
        "print(\"\\nSample data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Create Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "print(f\"\\nCreated Hugging Face dataset with {len(dataset)} examples\")\n",
        "\n",
        "# Save the dataset\n",
        "dataset.save_to_disk(\"./fhir_synthetic_dataset\")\n",
        "print(\"Dataset saved to './fhir_synthetic_dataset'\")\n",
        "\n",
        "# Also save as JSON for easy inspection\n",
        "with open(\"fhir_synthetic_data.json\", \"w\") as f:\n",
        "    json.dump(synthetic_data, f, indent=2)\n",
        "print(\"Dataset also saved as 'fhir_synthetic_data.json'\")\n",
        "\n",
        "# Show statistics\n",
        "resource_counts = df['resource_type'].value_counts()\n",
        "print(f\"\\nDataset statistics:\")\n",
        "print(f\"Total examples: {len(df)}\")\n",
        "print(f\"Unique resource types: {len(resource_counts)}\")\n",
        "print(f\"Examples per resource type (top 10):\")\n",
        "print(resource_counts.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
